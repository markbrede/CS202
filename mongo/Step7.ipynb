{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/markbrede/CS202/blob/main/mongo/Step7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "juKBjyXW27GK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91e374a5-dc26-4990-87f8-97c37108fed8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.106.160.119"
          ]
        }
      ],
      "source": [
        "# This will tell you your current IP address from google colab\n",
        "!curl api.ipify.org"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "kiMF8l-C27GL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "957eba00-4375-4e2b-af61-875e34118e29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.12/dist-packages (4.15.5)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from pymongo) (2.8.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "# Install needed python packages\n",
        "%pip install pymongo\n",
        "%pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "GtSopEVm27GL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60c8a601-a8fe-4776-a02c-af4b3c890a7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 99.9M  100 99.9M    0     0  5195k      0  0:00:19  0:00:19 --:--:-- 28.7M\n"
          ]
        }
      ],
      "source": [
        "# Download us-counties.csv\n",
        "!curl -L \"https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv\" > us-counties.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "VG6PEuzJ27GL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbb1aca1-c9bc-4b75-9c84-4e445420238d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ping result: {'ok': 1}\n"
          ]
        }
      ],
      "source": [
        "import pymongo\n",
        "\n",
        "user = \"ryliestoutrealestate_db_user\"\n",
        "password = \"Iom7JDFkTxI68lpc\"\n",
        "connectionUrl = f\"mongodb+srv://{user}:{password}@cluster0.hgw0jbr.mongodb.net/\"\n",
        "client = pymongo.MongoClient(connectionUrl)\n",
        "print(f\"Ping result: {client.admin.command('ping')}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ydLja9Qx27GL"
      },
      "outputs": [],
      "source": [
        "# Create or get your DB\n",
        "db_name = \"CS452_Mongo_Covid\"\n",
        "db = client.get_database(db_name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(db)\n"
      ],
      "metadata": {
        "id": "03BTcfjBqJtv",
        "outputId": "33bf4e1f-3602-471a-b59c-4187c038e08a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Database(MongoClient(host=['ac-wudie6j-shard-00-02.hgw0jbr.mongodb.net:27017', 'ac-wudie6j-shard-00-00.hgw0jbr.mongodb.net:27017', 'ac-wudie6j-shard-00-01.hgw0jbr.mongodb.net:27017'], document_class=dict, tz_aware=False, connect=True, authsource='admin', replicaset='atlas-14mxz2-shard-0', tls=True), 'CS452_Mongo_Covid')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0ySxj6e27GL"
      },
      "source": [
        "Spark SQL Rewrite in MongoDB 1-6\n",
        "\n",
        "*Redo the SparkSQL assignment in MongoDB using the aggregation pipeline.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "1zl0-JYC27GM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d3343da-db15-43e7-a886-cccbd46e950f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done\n"
          ]
        }
      ],
      "source": [
        "# 1. Write code to define the schema and then read in the dataset\n",
        "#    (took me 17 minutes!!!)\n",
        "\n",
        "import pandas\n",
        "\n",
        "# Load the CSV file\n",
        "df = pandas.read_csv('./us-counties.csv')\n",
        "data = df.to_dict('records')\n",
        "db.casesdeaths.drop()\n",
        "db.casesdeaths.insert_many(data)\n",
        "print(\"done\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "t92a6hJu27GM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71965048-5fe6-43b1-c9fe-b36a57795b2e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'_id': {'state': 'New York', 'county': 'New York City'},\n",
              "  'maxDeaths': 40267.0}]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# 2. Write code to find the county with the most deaths\n",
        "\n",
        "pipeline = [\n",
        "    # For each (state, county), get the maximum cumulative deaths over time\n",
        "    {\"$group\": {\n",
        "        \"_id\": {\"state\": \"$state\", \"county\": \"$county\"},\n",
        "        \"maxDeaths\": {\"$max\": \"$deaths\"}\n",
        "    }},\n",
        "    # Sort by that max descending\n",
        "    {\"$sort\": {\"maxDeaths\": -1}},\n",
        "    # Keep just the top one\n",
        "    {\"$limit\": 1}\n",
        "]\n",
        "\n",
        "res = list(db.casesdeaths.aggregate(pipeline))\n",
        "res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "p7cbpDme27GM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cee40d17-c7ac-48d1-c6dc-96b14a3b99cb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'_id': {'state': 'California', 'county': 'Los Angeles'},\n",
              "  'maxCases': 2908425}]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# 3. Write code to find the county with the most cases\n",
        "pipeline = [\n",
        "    # For each (state, county), get the maximum cumulative cases over time\n",
        "    {\"$group\": {\n",
        "        \"_id\": {\"state\": \"$state\", \"county\": \"$county\"},\n",
        "        \"maxCases\": {\"$max\": \"$cases\"}\n",
        "    }},\n",
        "    # Sort by that max descending\n",
        "    {\"$sort\": {\"maxCases\": -1}},\n",
        "    # Keep just the top one\n",
        "    {\"$limit\": 1}\n",
        "]\n",
        "\n",
        "res = list(db.casesdeaths.aggregate(pipeline))\n",
        "res\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "K1DuyYhd27GM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efff249e-0fa7-46b7-d3a8-ea9f3f7dc683"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'_id': None, 'totalDeaths': 270727.0}]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# 4. Write code to find the total number of deaths in Utah county\n",
        "pipeline = [\n",
        "    # Specify Utah and filter to Utah County\n",
        "    {\"$match\": {\"state\": \"Utah\", \"county\": \"Utah\"}},\n",
        "    # Sum all deaths across all dates\n",
        "    {\"$group\": {\n",
        "        \"_id\": None,\n",
        "        \"totalDeaths\": {\"$sum\": \"$deaths\"}\n",
        "    }}\n",
        "]\n",
        "\n",
        "res = list(db.casesdeaths.aggregate(pipeline))\n",
        "res\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "0-g4z74Q27GM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97ec0520-d3c1-4299-aa84-cde8beb24450"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'state': 'New Jersey', 'deathRate': 0.024599314263195268},\n",
              " {'state': 'New York', 'deathRate': 0.023269473447399408},\n",
              " {'state': 'Connecticut', 'deathRate': 0.022951919989349933},\n",
              " {'state': 'Massachusetts', 'deathRate': 0.022150657551530704},\n",
              " {'state': 'Pennsylvania', 'deathRate': 0.020515498386079523},\n",
              " {'state': 'Mississippi', 'deathRate': 0.019581229201172612},\n",
              " {'state': 'Michigan', 'deathRate': 0.01939462932342962},\n",
              " {'state': 'Louisiana', 'deathRate': 0.019116731017035902},\n",
              " {'state': 'Maryland', 'deathRate': 0.01867546574701237},\n",
              " {'state': 'District of Columbia', 'deathRate': 0.017972579316011646}]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "# 5. Write code to find the death rate for each state and sort the states by death rate descending\n",
        "pipeline = [\n",
        "    # Groups by state and sums the total cases and total deaths\n",
        "    {\"$group\": {\n",
        "        \"_id\": \"$state\",\n",
        "        \"totalCases\": {\"$sum\": \"$cases\"},\n",
        "        \"totalDeaths\": {\"$sum\": \"$deaths\"}\n",
        "    }},\n",
        "    # Finds death rate by deaths / cases\n",
        "    {\"$project\": {\n",
        "        \"_id\": 0,\n",
        "        \"state\": \"$_id\",\n",
        "        \"deathRate\": {\n",
        "            \"$cond\": [\n",
        "                {\"$eq\": [\"$totalCases\", 0]},\n",
        "                0,\n",
        "                {\"$divide\": [\"$totalDeaths\", \"$totalCases\"]}\n",
        "            ]\n",
        "        }\n",
        "    }},\n",
        "    # Sort by death rate descending\n",
        "    {\"$sort\": {\"deathRate\": -1}}\n",
        "]\n",
        "\n",
        "res = list(db.casesdeaths.aggregate(pipeline))\n",
        "# Top 10\n",
        "res[:10]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "c9eFXkhZ27GM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d03d115-6d7b-45fa-c1ea-f80f0edf595c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'totalDeaths': 36935467.0, 'state': 'California'},\n",
              " {'totalDeaths': 35976831.0, 'state': 'New York'},\n",
              " {'totalDeaths': 34210783.0, 'state': 'Texas'},\n",
              " {'totalDeaths': 27239119.0, 'state': 'Florida'},\n",
              " {'totalDeaths': 17686178.0, 'state': 'Pennsylvania'},\n",
              " {'totalDeaths': 17527511.0, 'state': 'New Jersey'},\n",
              " {'totalDeaths': 16325451.0, 'state': 'Illinois'},\n",
              " {'totalDeaths': 13824051.0, 'state': 'Michigan'},\n",
              " {'totalDeaths': 13673489.0, 'state': 'Georgia'},\n",
              " {'totalDeaths': 13146201.0, 'state': 'Ohio'}]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "# 6. Write code to something else interesting with this data â€“ your choice\n",
        "'''I think it would be cool to return the top 10 states for total deaths since I can make some educated guesses and see if they are true.\n",
        "My guess is that states with large cities (California, New York, etc) will be what makes up the top 10'''\n",
        "\n",
        "pipeline = [\n",
        "    {\"$group\": {\n",
        "        \"_id\": \"$state\",\n",
        "        \"totalDeaths\": {\"$sum\": \"$deaths\"}\n",
        "    }},\n",
        "    {\"$sort\": {\"totalDeaths\": -1}},\n",
        "    {\"$limit\": 10},\n",
        "    {\"$project\": {\"_id\": 0, \"state\": \"$_id\", \"totalDeaths\": 1}}\n",
        "]\n",
        "\n",
        "res = list(db.casesdeaths.aggregate(pipeline))\n",
        "res\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMVqLsdx27GM"
      },
      "source": [
        "In this next part we will get experience using MongoDB's aggegregation pipeline's $lookup stage to join collections in MongoDb. Specifically we'll join to our **cases/deaths data** with **[vaccination data](https://ourworldindata.org/us-states-vaccinations#what-share-of-the-population-has-completed-the-initial-vaccination-protocol)** and **[total population data](https://www2.census.gov/programs-surveys/popest/datasets/2010-2019/counties/totals/co-est2019-alldata.csv)**.  First we need to download and ingest the data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "6JceEIly27GM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91bcd753-9dae-482d-c3e1-e3fb6495fb4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 4804k  100 4804k    0     0  8411k      0 --:--:-- --:--:-- --:--:-- 8429k\n"
          ]
        }
      ],
      "source": [
        "# Get the CSV for covid vaccination data\n",
        "!curl -L \"https://raw.githubusercontent.com/owid/covid-19-data/master/public/data/vaccinations/us_state_vaccinations.csv\" > \"./us_state_vaccinations.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ntsf916g27GM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "collapsed": true,
        "outputId": "aa610a2e-fdd1-4eb1-bd41-07eecaef63e9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'csv' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1968265347.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Put the vaccinations data into the the DB  (took me 37 seconds)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./us_state_vaccinations.csv\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mdataRows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDictReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvaccinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert_many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataRows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'csv' is not defined"
          ]
        }
      ],
      "source": [
        "# Put the vaccinations data into the the DB  (took me 37 seconds)\n",
        "with open(\"./us_state_vaccinations.csv\") as f:\n",
        "  dataRows = csv.DictReader(f)\n",
        "  db.vaccinations.insert_many(dataRows)\n",
        "\n",
        "df = pandas.read_csv('./us_state_vaccinations.csv')\n",
        "data = df.to_dict('records')\n",
        "db.vaccinations.drop()\n",
        "db.vaccinations.insert_many(data)\n",
        "print(\"Done!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4Jfqf_827GN"
      },
      "outputs": [],
      "source": [
        "# Get the total population (Use POPESTIMATE2019)\n",
        "!curl -L \"https://www2.census.gov/programs-surveys/popest/datasets/2010-2019/counties/totals/co-est2019-alldata.csv\" > \"./co-est2019-alldata.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "-sgf65X427GN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "7b975a14-dd85-422f-d5b8-f0c70498ebd1"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './co-est2019-alldata.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3547656607.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#   db.population.insert_many(dataRows)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./co-est2019-alldata.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latin-1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'records'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopulations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './co-est2019-alldata.csv'"
          ]
        }
      ],
      "source": [
        "# Put population data into the DB (took me 10 seconds)\n",
        "# with open(\"./co-est2019-alldata.csv\", encoding='latin-1') as f:\n",
        "#   dataRows = csv.DictReader(f)\n",
        "#   db.population.insert_many(dataRows)\n",
        "\n",
        "df = pandas.read_csv('./co-est2019-alldata.csv', encoding='latin-1')\n",
        "data = df.to_dict('records')\n",
        "db.populations.drop()\n",
        "db.populations.insert_many(data)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''Build casesdeaths_state: one document per STATE with total cases/deaths'''\n",
        "\n",
        "pipeline = [\n",
        "    {\n",
        "        # For each (state, county), get the max cases/deaths over time\n",
        "        \"$group\": {\n",
        "            \"_id\": {\"state\": \"$state\", \"county\": \"$county\"},\n",
        "            \"maxCases\": {\"$max\": \"$cases\"},\n",
        "            \"maxDeaths\": {\"$max\": \"$deaths\"},\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        # Now sum those county maxes up to the state level\n",
        "        \"$group\": {\n",
        "            \"_id\": \"$_id.state\",\n",
        "            \"cases\": {\"$sum\": \"$maxCases\"},\n",
        "            \"deaths\": {\"$sum\": \"$maxDeaths\"},\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        # Clean up the shape\n",
        "        \"$project\": {\n",
        "            \"_id\": 0,\n",
        "            \"state\": \"$_id\",\n",
        "            \"cases\": 1,\n",
        "            \"deaths\": 1,\n",
        "        }\n",
        "    }\n",
        "]\n",
        "\n",
        "db.casesdeaths_state.drop()\n",
        "state_docs = list(db.casesdeaths.aggregate(pipeline))\n",
        "db.casesdeaths_state.insert_many(state_docs)\n",
        "\n",
        "print(\"states in casesdeaths_state:\", db.casesdeaths_state.count_documents({}))\n",
        "print(db.casesdeaths_state.find_one())\n"
      ],
      "metadata": {
        "id": "t_-ognQaROvk",
        "outputId": "9acc6ec4-e46b-4ff6-9e49-f065898e87a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "states in casesdeaths_state: 56\n",
            "{'_id': ObjectId('6930b5afd55d3d7bb6618e22'), 'cases': 1304721, 'deaths': 19629.0, 'state': 'Alabama'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5xRDuY827GN"
      },
      "source": [
        "Using the aggregation pipeline and the \\$out stage create a new dataset that just maps the state to total counts. Do this for all three data sets so you have:\n",
        "\n",
        "casesdeaths_state = (state, cases, deaths)\n",
        "\n",
        "populations_state = (state, population)\n",
        "\n",
        "vaccinations_state = (state, vaccinations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9iTKTUy27GN"
      },
      "outputs": [],
      "source": [
        "# Create the casesdeaths_state collection (remember the counties have a running sum by date, taking the max of each county, then summing by state is correct math)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5W1U_Rl-27GN"
      },
      "outputs": [],
      "source": [
        "# Create the populations_state collection (this dataset is interesting in that there is a \"county 0\" in each state that represents the state population total)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bjb3Z6wX27GN"
      },
      "outputs": [],
      "source": [
        "# Create the vaccinations_state collection (this dataset is by state and date. You don't want the sum of all the dates, as the data is a running sum)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1jGKNzE27GN"
      },
      "source": [
        "Use the \\$lookup stage of the aggregation pipeline to join your three data sets by state. Note this won't be a perfect join - to find out why look at the states or even the count of states in each set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7gYFfQ7f27GN"
      },
      "outputs": [],
      "source": [
        "# Report the state, infection rate (cases/population), death rate (deaths/population), vaccination rate (vaccinated_people/population)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GO8oFDwW27GN"
      },
      "outputs": [],
      "source": [
        "# Is there a correlation between infection or death rates with the vaccination rate for each state?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SMYf7z3827GN"
      },
      "outputs": [],
      "source": [
        "# Ask an interesting question that might be answered with this dataset and answer it."
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}